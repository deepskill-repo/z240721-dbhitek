{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent (경사 하강법)\n",
    "\n",
    "Gradient descent는 머신러닝에서 가장 널리 사용되는 최적화 알고리즘 중 하나입니다. 이 알고리즘은 모델의 오차를 최소화하는 파라미터를 찾는 데 사용됩니다.\n",
    "\n",
    "Gradient descent를 이해하기 위해 다음과 같은 비유를 생각해 봅시다:\n",
    "\n",
    "1. 당신이 안개 낀 산 정상에 있다고 상상해보세요. 목표는 가장 낮은 곳(계곡)을 찾는 것입니다. 하지만 안개 때문에 멀리 볼 수 없습니다. 어떻게 하시겠습니까?\n",
    "2. 현재 위치에서 주변을 살펴봅니다.\n",
    "3. 가장 가파르게 내려가는 방향을 찾습니다.\n",
    "4. 그 방향으로 조금 이동합니다.\n",
    "\n",
    "새로운 위치에서 1-3 단계를 반복합니다.\n",
    "이것이 바로 gradient descent의 기본 아이디어입니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def f(x, y):\n",
    "    return (x**2 + y**2) / 2\n",
    "\n",
    "x = np.linspace(-5, 5, 100)\n",
    "y = np.linspace(-5, 5, 100)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = f(X, Y)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.contour(X, Y, Z, levels=20)\n",
    "plt.colorbar(label='고도')\n",
    "plt.title('Gradient Descent 시각화')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "\n",
    "# Gradient descent 경로 표시\n",
    "path_x = [-4, -3, -2, -1, -0.5, -0.2, -0.1]\n",
    "path_y = [3, 2, 1.5, 1, 0.5, 0.2, 0.1]\n",
    "plt.plot(path_x, path_y, 'ro-', linewidth=2, markersize=8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 그래프에서:\n",
    "\n",
    "- 등고선은 \"고도\"를 나타냅니다 (우리의 비유에서 산의 높이).\n",
    "- 빨간 점들은 gradient descent 알고리즘이 취하는 경로를 보여줍니다.\n",
    "- 알고리즘은 가장 가파른 경사를 따라 내려가며 점점 계곡(최소값)에 가까워집니다.\n",
    "\n",
    "## Gradient Descent 단계\n",
    "\n",
    "1. **초기화**: 임의의 지점에서 시작합니다.\n",
    "2. **기울기 계산**: 현재 위치에서의 기울기를 계산합니다.\n",
    "3. **이동**: 기울기의 반대 방향으로 작은 스텝을 이동합니다.\n",
    "4. **반복**: 최소값에 도달하거나 정해진 반복 횟수에 도달할 때까지 2-3 단계를 반복합니다.\n",
    "\n",
    "## 학습률 (Learning Rate)\n",
    "\n",
    "학습률은 각 단계에서 얼마나 큰 스텝을 밟을지 결정합니다:\n",
    "\n",
    "- 너무 크면: 최소값을 지나칠 수 있습니다.\n",
    "- 너무 작으면: 수렴하는 데 오래 걸립니다.\n",
    "\n",
    "적절한 학습률을 선택하는 것이 중요합니다!\n",
    "\n",
    "## 결론\n",
    "\n",
    "Gradient descent는 \"산을 내려가는\" 것과 같은 직관적인 방법으로 최적의 해답을 찾아가는 알고리즘입니다. 복잡한 문제에서도 이 간단한 아이디어를 확장하여 적용할 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
